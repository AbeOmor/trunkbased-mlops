{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1fb6617",
   "metadata": {},
   "source": [
    "# Running the model locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ffe98",
   "metadata": {},
   "source": [
    "The following line will move the notebook to the root directory of the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba60426d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/santiagxf/repos/devsquad/trunkbased-mlops/src\n"
     ]
    }
   ],
   "source": [
    "cd ../src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef7377",
   "metadata": {},
   "source": [
    "## Authenticating against Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c269799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a22387de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"b2fbd4a8-a281-4bb1-b839-f18277513787\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96fb898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config(path='../workspaces/dev/workspace.json', auth=interactive_auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2905da3",
   "metadata": {},
   "source": [
    "## Running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22858e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hatedetection.score.score_transformer as scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a665a3",
   "metadata": {},
   "source": [
    "We re indicating `from_workspace` to indicate that this model is running locally, and `ws` indicates the workspace from where the model will be pulled from:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a82453",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:[WARN] Opening model from workspace\n"
     ]
    }
   ],
   "source": [
    "scorer.init(from_workspace=True, workspace=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f453c36f",
   "metadata": {},
   "source": [
    "> Note: This may take a while since the model is quite big (1.24 GB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3349fdb1",
   "metadata": {},
   "source": [
    "Loading some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd1a33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96b11fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/relatus-hate-speech-text/data/speechs-sample.csv').drop(columns=['hate']).loc[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8128751",
   "metadata": {},
   "source": [
    "Running the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f15dbcb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6059866547584534,\n",
       " 0.30062082409858704,\n",
       " 0.4073381721973419,\n",
       " 0.6878570318222046,\n",
       " 0.2586149275302887,\n",
       " 0.6854346394538879]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.run(raw_data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0ef4bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hatedetection.model.evaluation import compare\n",
    "from common.models.model_management import get_model\n",
    "import azureml.core as aml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89cd68cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset = '../datasets/portuguese-hate-speech-tweets-eval/data/2019-05-28_portuguese_hate_speech_hierarchical_classification.csv'\n",
    "confidence = 0.05\n",
    "model_name = 'hate-pt-speech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9e14ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    }
   ],
   "source": [
    "ws = aml.Workspace.from_config('../workspaces/dev/workspace.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4b33e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "champion_model = get_model(ws, 'hate-pt-speech', version=\"stage=production\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "150ea6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_model = get_model(ws, 'hate-pt-speech', version=\"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65566c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "champion_path = champion_model.download(\"champion\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7716d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenger_path = challenger_model.download(\"challenger\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e1edf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6458/864018976.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchampion_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchallenger_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfidence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/repos/devsquad/trunkbased-mlops/src/hatedetection/model/evaluation.py\u001b[0m in \u001b[0;36mcompare\u001b[0;34m(champion_path, challenger_path, eval_dataset, confidence)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] Unloading champion object from memory\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mchampion_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mchallenger_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHateDetectionClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformers-torch-19-dev/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36msynchronize\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \"\"\"\n\u001b[0;32m--> 444\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_synchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/transformers-torch-19-dev/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "compare(champion_path, challenger_path, eval_dataset, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2fa7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import hatedetection.model.hate_detection_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4fb147a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'hatedetection.model.hate_detection_classifier' from '/home/santiagxf/repos/devsquad/trunkbased-mlops/src/hatedetection/model/hate_detection_classifier.py'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(hatedetection.model.hate_detection_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d332d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (transformers-torch-19-dev)",
   "language": "python",
   "name": "transformers-torch-19-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
